{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "from hail.plot import show\n",
    "from pprint import pprint\n",
    "\n",
    "hl.init(default_reference = \"GRCh38\", min_block_size=128, \n",
    "        spark_conf={'spark.driver.memory': '40g', 'spark.task.maxFailures': '20', 'spark.master': 'local[20,20]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder with raw VCFs\n",
    "data_dir = '~/WGS/BRAVA/raw_data_exome_f3/'  # raw VCFs\n",
    "mt_dir = '~/WGS/BRAVA/mt/' #MTs converted from VCF\n",
    "checkpoint_dir = '~/WGS/BRAVA/checkpoint/' # folder with intermediate files (filtered by GT and variant)\n",
    "filtered_dir = '~/WGS/BRAVA/filtered/' # final filtered QC MT\n",
    "\n",
    "# Loading resources\n",
    "# Import the interval lists for the target intervals.\n",
    "target_intervals = hl.import_locus_intervals('~/WGS/BRAVA/Exome_QC_Hail/resources/twist_comprehensive_exome_hg38_one_based.txt', reference_genome='GRCh38')\n",
    "# Import the interval lists for the padded target intervals.\n",
    "padded_target_intervals = hl.import_locus_intervals('~/WGS/BRAVA/Exome_QC_Hail/resources/twist_comprehensive_exome_hg38__one_based_50bp_padded.txt', reference_genome='GRCh38')\n",
    "# Import the interval lists for the LCRs.\n",
    "LCR_intervals = hl.import_locus_intervals('~/WGS/BRAVA/Exome_QC_Hail/resources/LCR-hs38.bed', reference_genome='GRCh38')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromosome[s) to run\n",
    "chrom = ['6', '7', '8', '9', '10', '11', '12', '13', '18', 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting VCF chunks to chromosome MTs \n",
    "# files are bgzipped but the extension is .gz, therefore, using force_bgz=True\n",
    "# there are some multialleleic sites the are malformed, therefore using skip_invalid_loci=True\n",
    "# array_elements_required=False is to import variants with missing data\n",
    "\n",
    "import glob, re\n",
    "for chr in chrom:\n",
    "\n",
    "    #outputs\n",
    "    MT = mt_dir + 'chr' + chr + '.mt' # raw MT imports from VCFs\n",
    "    \n",
    "    # getting file paths for chromosome chunks\n",
    "    chr_files = glob.glob(data_dir + '*_chr' + chr +'_*')\n",
    "    chr_files.sort()\n",
    "\n",
    "\n",
    "    # removing index files from the list of chunks\n",
    "    chr_files = [item for item in chr_files if not re.search(r\"csi\", item)]\n",
    "\n",
    "    hl.import_vcf(chr_files, reference_genome='GRCh38', force_bgz=True, find_replace=('nul', '.'),\n",
    "              skip_invalid_loci=True,\n",
    "              array_elements_required=False).write(MT, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotating variants in padded target intervals \n",
    "# removing multialleleic sites > 6\n",
    "# splitting multialleleic sites \n",
    "# Ffiltering by genotype quality, repartitioning and saving\n",
    "\n",
    "for chr in chrom:\n",
    "\n",
    "    # inputs\n",
    "    MT = mt_dir + 'chr' + chr + '.mt' # raw MT imports from VCFs\n",
    "\n",
    "    # outputs\n",
    "    MT_GT_MULTI = checkpoint_dir + 'chr' + chr + '.GT_multi.mt' # MT after filtering by genotype and splitting MA sites\n",
    "    MT_GT_MULTI_HARDCALLS = checkpoint_dir + 'chr' + chr + '.GT_multi.hardcalls.mt' # Genotypes only\n",
    "    \n",
    "    mt = hl.read_matrix_table(MT)\n",
    "\n",
    "    # 1. Initial count.\n",
    "    n = mt.count()\n",
    "    print('Chromosome ' + chr +\": \" + str(n))\n",
    "\n",
    "    # 2. Annotate variants that are not in padded target interval.\n",
    "    mt = mt.annotate_rows(not_in_padded_target_intervals = ~hl.is_defined(padded_target_intervals[mt.locus]))\n",
    "\n",
    "    # Get information about the number of variants that were excluded.\n",
    "    not_in_padded_target_intervals = mt.filter_rows(mt.not_in_padded_target_intervals).count_rows()\n",
    "\n",
    "    print('')\n",
    "    print('Chromosome ' + chr + ': n variants not in padded target intervals:')\n",
    "    pprint(not_in_padded_target_intervals)\n",
    "\n",
    "    print('')\n",
    "    print('Chromosome ' + chr + ':% of variants not in padded target intervals marked:')\n",
    "    pprint(not_in_padded_target_intervals/n[0]*100)\n",
    "\n",
    "    # 3. Removing multiallelic sites with > 6 alleles.\n",
    "    n = mt.count_rows()\n",
    "    pprint('')\n",
    "    pprint('Chromosome ' + chr + ': All variants: ' + str(n))\n",
    "\n",
    "    mt = mt.filter_rows(mt.alleles.length() <= 6)\n",
    "\n",
    "    n = mt.count_rows()\n",
    "    pprint('')\n",
    "    pprint('Chromosome ' + chr + ': n variants not more than 6 alleles:' + str(n))\n",
    "    print(n)\n",
    "\n",
    "    # 4. Splitting multiallelic sites\n",
    "    mt = hl.split_multi_hts(mt)\n",
    "    \n",
    "    # 5. Filtering by genotype quality, repartitioning and saving\n",
    "    \n",
    "    mt = mt.filter_entries(\n",
    "        hl.is_defined(mt.GT) &\n",
    "        (\n",
    "            (mt.GT.is_hom_ref() & \n",
    "                (\n",
    "                    # ((mt.AD[0] / mt.DP) < 0.8) | # Has to be removed because allele depth no longer defined for hom ref calls.\n",
    "                    (mt.GQ < 20) |\n",
    "                    (mt.DP < 10)\n",
    "                )\n",
    "            ) |\n",
    "            (mt.GT.is_het() & \n",
    "                ( \n",
    "                    (((mt.AD[0] + mt.AD[1]) / mt.DP) < 0.8) | \n",
    "                    ((mt.AD[1] / mt.DP) < 0.2) | \n",
    "                    (mt.PL[0] < 20) |\n",
    "                    (mt.DP < 10)\n",
    "                )\n",
    "            ) |\n",
    "            (mt.GT.is_hom_var() & \n",
    "                (\n",
    "                    ((mt.AD[1] / mt.DP) < 0.8) |\n",
    "                    (mt.PL[0] < 20) |\n",
    "                    (mt.DP < 10)\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "        keep = False\n",
    "    )\n",
    "\n",
    "\n",
    "    # saving full filtere and split matrix table with genotypes\n",
    "    mt = mt.checkpoint(MT_GT_MULTI, overwrite=True)\n",
    "\n",
    "    # saving just genotypes (hard calls)\n",
    "    mt = hl.read_matrix_table(MT_GT_MULTI)\n",
    "    mt.select_entries(mt.GT).repartition(512).write(MT_GT_MULTI_HARDCALLS, overwrite=True)\n",
    "\n",
    "    mt = hl.read_matrix_table(MT_GT_MULTI_HARDCALLS)\n",
    "    n = mt.count()\n",
    "\n",
    "\n",
    "    pprint('Chromosome ' + chr + ' n samples:' + str(n[1]))\n",
    "    pprint('Chromosome ' + chr + ' n variants:' + str(n[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chr in chrom:\n",
    "\n",
    "    # inputs\n",
    "    MT = mt_dir + 'chr' + chr + '.mt' # raw MT imports from VCFs\n",
    "    MT_GT_MULTI = checkpoint_dir + 'chr' + chr + '.GT_multi.mt' # MT after filtering by genotype and splitting MA sites\n",
    "    MT_GT_MULTI_HARDCALLS = checkpoint_dir + 'chr' + chr + '.GT_multi.hardcalls.mt' # Genotypes only\n",
    "\n",
    "    # outputs\n",
    "    INITIAL_VARIANT_QC_FILE  = './prefilter_metrics/chr' + chr + '_prefilter_metrics.tsv'\n",
    "    INITIAL_VARIANT_LIST = './prefilter_metrics/chr' + chr + '.keep.variant_list'\n",
    "    # INITIAL_SAMPLE_QC_FILE = 'gs://hail-brava/prefilter_metrics/COLORADO_Freeze_Two.chr' + chr + '.initial_sample_qc.tsv'\n",
    "\n",
    "    FILTERED_MT = checkpoint_dir + 'chr' + chr + '.GT_multi.variant.filtered.mt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # 1. Loading genotype hardcalls\n",
    "    mt = hl.read_matrix_table(MT_GT_MULTI_HARDCALLS)\n",
    "    \n",
    "    # 2. Counting the number of variants before filtering by variant\n",
    "    n = mt.count()\n",
    "    print('Chromosome ' + chr +\" before filtering by variant: \" + str(n))\n",
    "\n",
    "    \n",
    "    # 3. Annotating variants with flag indicating if they are in LCR or failed VQSR.\n",
    "    mt = mt.annotate_rows(fail_VQSR = (hl.len(mt.filters) != 0) & ~hl.is_missing(mt.filters))\n",
    "    mt = mt.annotate_rows(in_LCR = hl.is_defined(LCR_intervals[mt.locus]))\n",
    "    mt = mt.annotate_rows(not_in_target_intervals = ~hl.is_defined(target_intervals[mt.locus]))\n",
    "    mt = mt.annotate_rows(not_in_padded_target_intervals = ~hl.is_defined(padded_target_intervals[mt.locus]))\n",
    "\n",
    "    # Get information about the number of variants that will be excluded.\n",
    "    fail_VQSR = mt.filter_rows(mt.fail_VQSR).count_rows()\n",
    "    in_LCR = mt.filter_rows(mt.in_LCR).count_rows()\n",
    "    not_in_target_intervals = mt.filter_rows(mt.not_in_target_intervals).count_rows()\n",
    "    not_in_padded_target_intervals = mt.filter_rows(mt.not_in_padded_target_intervals).count_rows()\n",
    "\n",
    "    print('Chromosome ' + chr + ': n variants failing VQSR: ' + str(fail_VQSR))\n",
    "    print('Chromosome ' + chr + ': n variants in low complexity regions:' + str(in_LCR))\n",
    "    print('Chromosome ' + chr + ': n variants not in target intervals:' + str(not_in_target_intervals))\n",
    "    print('Chromosome ' + chr + ': n variants not in padded target intervals:' + str(not_in_padded_target_intervals))\n",
    "    \n",
    "    \n",
    "    # 4. Variant filtering.\n",
    "    # removing failed VQSR, variants in LCR and variant outside of padded target intervals\n",
    "    mt_rows = mt.rows()\n",
    "    mt_rows.select(mt_rows.fail_VQSR, mt_rows.in_LCR, mt_rows.not_in_padded_target_intervals).export(INITIAL_VARIANT_QC_FILE)\n",
    "    mt = mt.filter_rows(mt.fail_VQSR | mt.in_LCR | mt.not_in_padded_target_intervals, keep=False)\n",
    "\n",
    "    # removing variants not in 24 canonical chromosomes\n",
    "    intervals = [hl.parse_locus_interval(x, reference_genome='GRCh38') for x in ['chr1:START-chr22:END', 'chrX:START-chrX:END', 'chrY:START-chrY:END']]\n",
    "    mt = hl.filter_intervals(mt, intervals)\n",
    "\n",
    "    # removing invariant rows.\n",
    "    mt = hl.variant_qc(mt, name='qc')\n",
    "    mt = mt.filter_rows((mt.qc.AF[0] > 0.0) & (mt.qc.AF[0] < 1.0))\n",
    "\n",
    "    # saving list of variants that passed QC\n",
    "    mt_rows_filter = mt.rows().select().export(INITIAL_VARIANT_LIST)\n",
    "\n",
    "    n_variants = hl.import_table(INITIAL_VARIANT_LIST).count()\n",
    "\n",
    "    print('Chromosome ' + chr + ': n variants after filter:' + str(n_variants))\n",
    "   \n",
    "    # saving filtered mt for chromosome\n",
    "    mt.write(FILTERED_MT, overwrite = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating sample QC metrics by chromosome\n",
    "\n",
    "for chr in chrom:\n",
    "    #inputs\n",
    "    MT_GT_MULTI = checkpoint_dir + 'chr' + chr + '.GT_multi.mt'\n",
    "    INITIAL_VARIANT_LIST = './prefilter_metrics/chr' + chr + '.keep.variant_list'\n",
    "\n",
    "    #outputs\n",
    "    INITIAL_SAMPLE_QC_FILE = './sample_QC/chr' + chr + '_initial_sample_qc.tsv'\n",
    "\n",
    "    # sample QC is done on the full MT that has varianr level QC data\n",
    "    mt = hl.read_matrix_table(MT_GT_MULTI)\n",
    "\n",
    "    # loading list of variants that passed QC\n",
    "    variants_to_filter = hl.import_table(INITIAL_VARIANT_LIST,\n",
    "    \ttypes={'locus':hl.tlocus(reference_genome='GRCh38'), 'alleles':hl.tarray(hl.tstr)})\n",
    "    variants_to_filter = variants_to_filter.key_by(locus=variants_to_filter.locus, alleles=variants_to_filter.alleles)\n",
    "    \n",
    "    \n",
    "    mt = mt.filter_rows(hl.is_defined(variants_to_filter[mt.row_key]))\n",
    "    \n",
    "    n = mt.count()\n",
    "    pprint('n samples:')\n",
    "    print(n[1])\n",
    "    pprint('n variants:')\n",
    "    print(n[0])\n",
    "\n",
    "    \n",
    "    mt = hl.sample_qc(mt, name='qc_padded_twist')\n",
    "    \n",
    "    mt = mt.annotate_rows(not_in_target_intervals = ~hl.is_defined(target_intervals[mt.locus]))\n",
    "    mt = mt.filter_rows(mt.not_in_target_intervals, keep=False)\n",
    "    \n",
    "    n = mt.count()\n",
    "    \n",
    "    pprint('n samples:')\n",
    "    print(n[1])\n",
    "    pprint('n variants:')\n",
    "    print(n[0])\n",
    "    \n",
    "    mt = hl.sample_qc(mt, name='qc_twist')\n",
    "    \n",
    "    mt.cols().select('qc_padded_twist', 'qc_twist').flatten().export(output=INITIAL_SAMPLE_QC_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.spark_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
